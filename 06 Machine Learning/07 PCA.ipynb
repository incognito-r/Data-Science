{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA):\n",
    "rincipal Component Analysis (PCA) is a dimensionality reduction technique widely used in machine learning and data analysis. It transforms high-dimensional data into a lower-dimensional space while retaining as much variance (information) as possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How PCA Works:\n",
    "\n",
    "- Standardize the Data: Scale the data to have zero mean and unit variance (if needed).\n",
    "- Compute the Covariance Matrix: Calculate the covariance matrix to understand relationships between features.\n",
    "- Find Eigenvectors and Eigenvalues: Determine the principal components by computing eigenvectors (directions of maximum variance) and eigenvalues (magnitude of variance).\n",
    "- Project Data: Transform the original data onto the new subspace defined by the top K principal components (those with the highest eigenvalues)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applications:\n",
    "\n",
    "- Image compression\n",
    "- Gene expression data analysis\n",
    "- Data preprocessing for machine learning models\n",
    "- Visualizing high-dimensional datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
