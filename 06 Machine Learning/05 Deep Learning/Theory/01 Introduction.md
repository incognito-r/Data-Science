# Introduction to Deep Learning
Deep Learning is a subset of machine learning focused on algorithms inspired by the structure and function of the brain, known as artificial neural networks. These models learn directly from data and improve automatically through experience.

## üß¨ Deep Learning vs Traditional ML
| Aspect                  | Traditional ML          | Deep Learning           |
| ----------------------- | ----------------------- | ----------------------- |
| **Feature engineering** | Manual                  | Automated               |
| **Performance**         | Plateaus with more data | Improves with more data |
| **Interpretability**    | More interpretable      | Often a black box       |
| **Data requirement**    | Less data               | Needs large datasets    |
| **Computation**         | Light                   | Heavy (GPU/TPU needed)  |


## ‚öôÔ∏è Components of a Deep Learning System
Data: Raw input like images, audio, text.

Model: Neural network architecture.

Loss Function: Quantifies how well the model is doing.

Optimizer: Adjusts model parameters to minimize the loss.

Training Process: Iterative process using backpropagation and gradient descent.

## üî¨ Real-World Applications

| Domain                                | Examples                                                   |
| ------------------------------------- | ---------------------------------------------------------- |
| **Computer Vision**                   | Image classification, object detection, facial recognition |
| **Natural Language Processing (NLP)** | Chatbots, translation, sentiment analysis                  |
| **Speech**                            | Speech recognition, voice assistants                       |
| **Healthcare**                        | Disease diagnosis from scans, drug discovery               |
| **Autonomous Systems**                | Self-driving cars, robotics                                |
| **Finance**                           | Fraud detection, market prediction                         |

## üß© Key Terminology
- Epoch: One complete pass through the training data.
- Batch size: Number of samples processed before model is updated.
- Iteration: One update step (batch-wise).
- Parameters: Weights and biases learned by the model.
- Hyperparameters: Tunable settings like learning rate, number of layers.
- Layer depth: Number of hidden layers
- Width: Number of neurons in a layer




